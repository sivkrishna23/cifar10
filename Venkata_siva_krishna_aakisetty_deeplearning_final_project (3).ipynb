{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7934f5ad3fa42a6a3e0e9d01dcf74e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bff47057fdc648b5bd11bf3fa300e8bc",
              "IPY_MODEL_6c3b0d2a632d4c27946987f4d27ef5f5",
              "IPY_MODEL_2ced38269ca84e50be868d892682f355"
            ],
            "layout": "IPY_MODEL_f8b913cfa2cf45df8bca5c2e97a8f2b8"
          }
        },
        "bff47057fdc648b5bd11bf3fa300e8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476d9f2df23d4d7b9dfc780476afb565",
            "placeholder": "​",
            "style": "IPY_MODEL_fe8f8ef5208a415cbe0b9be17544d1f1",
            "value": "model.safetensors: 100%"
          }
        },
        "6c3b0d2a632d4c27946987f4d27ef5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d005469841479a9ee7d2875f9974bc",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f111fb7114cb4c0f901a6172a1b4f84c",
            "value": 114286722
          }
        },
        "2ced38269ca84e50be868d892682f355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbae917dda34b0d8a19e8ec5fa39420",
            "placeholder": "​",
            "style": "IPY_MODEL_f4e5e6d3520e4968bca1db2b1b4f00d5",
            "value": " 114M/114M [00:00&lt;00:00, 198MB/s]"
          }
        },
        "f8b913cfa2cf45df8bca5c2e97a8f2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "476d9f2df23d4d7b9dfc780476afb565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8f8ef5208a415cbe0b9be17544d1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d005469841479a9ee7d2875f9974bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f111fb7114cb4c0f901a6172a1b4f84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bbae917dda34b0d8a19e8ec5fa39420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e5e6d3520e4968bca1db2b1b4f00d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For each and every model i read the data set into it, because im am facing some issues with kernal and my laptop computing power. for each model it takes 50-70 minutes to run for single modification , so itried morethen 25 modifications. following are the five models and their performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u4T15uoNiiBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DenseNet"
      ],
      "metadata": {
        "id": "0gUyQn-gVDjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# DenseNet building blocks\n",
        "def dense_block(x, num_layers, growth_rate):\n",
        "    for _ in range(num_layers):\n",
        "        cb = layers.BatchNormalization()(x)\n",
        "        cb = layers.Activation('relu')(cb)\n",
        "        cb = layers.Conv2D(growth_rate, 3, padding='same')(cb)\n",
        "        x = layers.Concatenate()([x, cb])\n",
        "    return x\n",
        "\n",
        "def transition_layer(x, compression):\n",
        "    filters = int(x.shape[-1] * compression)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters, 1, padding='same')(x)\n",
        "    x = layers.AveragePooling2D(2, strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def create_densenet_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = dense_block(x, 6, 32)\n",
        "    x = transition_layer(x, 0.5)\n",
        "\n",
        "    x = dense_block(x, 12, 32)\n",
        "    x = transition_layer(x, 0.5)\n",
        "\n",
        "    x = dense_block(x, 24, 32)\n",
        "    x = transition_layer(x, 0.5)\n",
        "\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "\n",
        "#  DenseNet model\n",
        "densenet_model = create_densenet_model()\n",
        "densenet_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = densenet_model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[lr_scheduler, early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "train_loss, train_accuracy = densenet_model.evaluate(x_train, y_train, verbose=0)\n",
        "test_loss, test_accuracy = densenet_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print(\"\\nDenseNet Model Results:\")\n",
        "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Training loss: {train_loss:.4f}\")\n",
        "print(f\"Testing loss: {test_loss:.4f}\")\n",
        "\n",
        "\n",
        "densenet_model.save('cifar10_densenet_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDCxX-uPPbkE",
        "outputId": "43972625-a9ed-4a21-9627-406afbc99e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 221ms/step - accuracy: 0.3576 - loss: 1.7613 - val_accuracy: 0.3164 - val_loss: 3.3974 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 140ms/step - accuracy: 0.5885 - loss: 1.1457 - val_accuracy: 0.3996 - val_loss: 2.3534 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 140ms/step - accuracy: 0.6787 - loss: 0.9190 - val_accuracy: 0.6677 - val_loss: 1.0163 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 139ms/step - accuracy: 0.7272 - loss: 0.7749 - val_accuracy: 0.6905 - val_loss: 1.0369 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.7701 - loss: 0.6630 - val_accuracy: 0.6981 - val_loss: 0.9260 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 133ms/step - accuracy: 0.7956 - loss: 0.5887 - val_accuracy: 0.7643 - val_loss: 0.7151 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.8181 - loss: 0.5275 - val_accuracy: 0.7468 - val_loss: 0.8985 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 134ms/step - accuracy: 0.8348 - loss: 0.4768 - val_accuracy: 0.6126 - val_loss: 1.5534 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 134ms/step - accuracy: 0.8456 - loss: 0.4476 - val_accuracy: 0.8240 - val_loss: 0.5421 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 138ms/step - accuracy: 0.8598 - loss: 0.4054 - val_accuracy: 0.7987 - val_loss: 0.6454 - learning_rate: 0.0010\n",
            "Epoch 11/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 138ms/step - accuracy: 0.8694 - loss: 0.3772 - val_accuracy: 0.8226 - val_loss: 0.5493 - learning_rate: 0.0010\n",
            "Epoch 12/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 134ms/step - accuracy: 0.8791 - loss: 0.3543 - val_accuracy: 0.7443 - val_loss: 0.9340 - learning_rate: 0.0010\n",
            "Epoch 13/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 132ms/step - accuracy: 0.8859 - loss: 0.3254 - val_accuracy: 0.7895 - val_loss: 0.6624 - learning_rate: 0.0010\n",
            "Epoch 14/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 133ms/step - accuracy: 0.8931 - loss: 0.3121 - val_accuracy: 0.7866 - val_loss: 0.7869 - learning_rate: 0.0010\n",
            "Epoch 15/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 134ms/step - accuracy: 0.9143 - loss: 0.2487 - val_accuracy: 0.8942 - val_loss: 0.3202 - learning_rate: 5.0000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.9229 - loss: 0.2233 - val_accuracy: 0.8719 - val_loss: 0.4356 - learning_rate: 5.0000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.9286 - loss: 0.2027 - val_accuracy: 0.8877 - val_loss: 0.3624 - learning_rate: 5.0000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.9296 - loss: 0.1985 - val_accuracy: 0.8967 - val_loss: 0.3378 - learning_rate: 5.0000e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.9342 - loss: 0.1857 - val_accuracy: 0.8798 - val_loss: 0.4129 - learning_rate: 5.0000e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 135ms/step - accuracy: 0.9343 - loss: 0.1880 - val_accuracy: 0.8929 - val_loss: 0.3332 - learning_rate: 5.0000e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 135ms/step - accuracy: 0.9483 - loss: 0.1507 - val_accuracy: 0.8976 - val_loss: 0.3375 - learning_rate: 2.5000e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 141ms/step - accuracy: 0.9526 - loss: 0.1358 - val_accuracy: 0.9112 - val_loss: 0.2858 - learning_rate: 2.5000e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 135ms/step - accuracy: 0.9543 - loss: 0.1296 - val_accuracy: 0.9041 - val_loss: 0.3263 - learning_rate: 2.5000e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 133ms/step - accuracy: 0.9555 - loss: 0.1264 - val_accuracy: 0.9081 - val_loss: 0.3021 - learning_rate: 2.5000e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 139ms/step - accuracy: 0.9596 - loss: 0.1156 - val_accuracy: 0.9195 - val_loss: 0.2704 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DenseNet Model Results:\n",
            "Training accuracy: 0.9731\n",
            "Testing accuracy: 0.9195\n",
            "Training loss: 0.0750\n",
            "Testing loss: 0.2704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epochs = list(range(1, 26))\n",
        "train_accuracy = [\n",
        "    0.3576, 0.5885, 0.6787, 0.7272, 0.7701, 0.7956, 0.8181, 0.8348, 0.8456, 0.8598,\n",
        "    0.8694, 0.8791, 0.8859, 0.8931, 0.9143, 0.9229, 0.9286, 0.9296, 0.9342, 0.9343,\n",
        "    0.9483, 0.9526, 0.9543, 0.9555, 0.9596\n",
        "]\n",
        "val_accuracy = [\n",
        "    0.3164, 0.3996, 0.6677, 0.6905, 0.6981, 0.7643, 0.7468, 0.6126, 0.8240, 0.7987,\n",
        "    0.8226, 0.7443, 0.7895, 0.7866, 0.8942, 0.8719, 0.8877, 0.8967, 0.8798, 0.8929,\n",
        "    0.8976, 0.9112, 0.9041, 0.9081, 0.9195\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy', color='blue', marker='o', markersize=4)\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy', color='orange', marker='s', markersize=4)\n",
        "\n",
        "plt.title('densenet Training and Validation Accuracy', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "plt.ylim(0.3, 1.0)\n",
        "\n",
        "plt.savefig('densenet_accuracy_plot.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "JxpD2ojCm6fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN"
      ],
      "metadata": {
        "id": "GnCS3oadiadv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# CNN model\n",
        "model = models.Sequential([\n",
        "    # Input layer\n",
        "    layers.Input(shape=(32, 32, 3)),\n",
        "\n",
        "    # First Conv Block\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    # Second Conv Block\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Third Conv Block\n",
        "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Dense Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[lr_scheduler, early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "model.save('cifar10_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk8GS9aPSe9B",
        "outputId": "f193d79f-f0a2-4b3c-ba08-cbb0afc7fe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 114ms/step - accuracy: 0.3347 - loss: 2.1915 - val_accuracy: 0.2507 - val_loss: 2.6463 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.5418 - loss: 1.3050 - val_accuracy: 0.5851 - val_loss: 1.2236 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.6407 - loss: 1.0243 - val_accuracy: 0.6834 - val_loss: 0.9726 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.6931 - loss: 0.8776 - val_accuracy: 0.7126 - val_loss: 0.8530 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 83ms/step - accuracy: 0.7246 - loss: 0.7833 - val_accuracy: 0.7255 - val_loss: 0.8337 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.7438 - loss: 0.7295 - val_accuracy: 0.7365 - val_loss: 0.8239 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7637 - loss: 0.6792 - val_accuracy: 0.7691 - val_loss: 0.6638 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.7790 - loss: 0.6393 - val_accuracy: 0.8088 - val_loss: 0.5708 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.7935 - loss: 0.5968 - val_accuracy: 0.8087 - val_loss: 0.5767 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7995 - loss: 0.5750 - val_accuracy: 0.7326 - val_loss: 0.8701 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 82ms/step - accuracy: 0.8089 - loss: 0.5529 - val_accuracy: 0.7659 - val_loss: 0.7310 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8325 - loss: 0.4882 - val_accuracy: 0.8196 - val_loss: 0.5406 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8418 - loss: 0.4535 - val_accuracy: 0.8513 - val_loss: 0.4513 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - accuracy: 0.8488 - loss: 0.4399 - val_accuracy: 0.8598 - val_loss: 0.4242 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.8533 - loss: 0.4241 - val_accuracy: 0.8307 - val_loss: 0.5110 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8559 - loss: 0.4159 - val_accuracy: 0.8619 - val_loss: 0.4110 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8591 - loss: 0.4018 - val_accuracy: 0.8583 - val_loss: 0.4373 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8625 - loss: 0.3969 - val_accuracy: 0.8656 - val_loss: 0.4053 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8663 - loss: 0.3860 - val_accuracy: 0.8723 - val_loss: 0.3779 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.8659 - loss: 0.3845 - val_accuracy: 0.8679 - val_loss: 0.4130 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.8694 - loss: 0.3729 - val_accuracy: 0.8249 - val_loss: 0.5740 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8752 - loss: 0.3599 - val_accuracy: 0.8778 - val_loss: 0.3646 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.8751 - loss: 0.3567 - val_accuracy: 0.8784 - val_loss: 0.3676 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 83ms/step - accuracy: 0.8794 - loss: 0.3495 - val_accuracy: 0.8733 - val_loss: 0.3867 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.8814 - loss: 0.3391 - val_accuracy: 0.8708 - val_loss: 0.3981 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8869 - loss: 0.3250 - val_accuracy: 0.8845 - val_loss: 0.3552 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8936 - loss: 0.3008 - val_accuracy: 0.8867 - val_loss: 0.3428 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8933 - loss: 0.3011 - val_accuracy: 0.8804 - val_loss: 0.3794 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8998 - loss: 0.2893 - val_accuracy: 0.8915 - val_loss: 0.3327 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.8991 - loss: 0.2923 - val_accuracy: 0.8934 - val_loss: 0.3283 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.9012 - loss: 0.2861 - val_accuracy: 0.8899 - val_loss: 0.3463 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.9016 - loss: 0.2752 - val_accuracy: 0.8891 - val_loss: 0.3425 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9017 - loss: 0.2781 - val_accuracy: 0.8919 - val_loss: 0.3381 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.9073 - loss: 0.2668 - val_accuracy: 0.8937 - val_loss: 0.3314 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 83ms/step - accuracy: 0.9114 - loss: 0.2609 - val_accuracy: 0.8931 - val_loss: 0.3294 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.9117 - loss: 0.2552 - val_accuracy: 0.8983 - val_loss: 0.3119 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9089 - loss: 0.2571 - val_accuracy: 0.8987 - val_loss: 0.3293 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9118 - loss: 0.2499 - val_accuracy: 0.8998 - val_loss: 0.3059 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.9144 - loss: 0.2426 - val_accuracy: 0.8996 - val_loss: 0.3255 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9164 - loss: 0.2376 - val_accuracy: 0.8985 - val_loss: 0.3315 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.9171 - loss: 0.2385 - val_accuracy: 0.9026 - val_loss: 0.3166 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.9168 - loss: 0.2396 - val_accuracy: 0.9060 - val_loss: 0.3020 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.9184 - loss: 0.2333 - val_accuracy: 0.9048 - val_loss: 0.2965 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.9159 - loss: 0.2382 - val_accuracy: 0.9055 - val_loss: 0.2965 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9202 - loss: 0.2339 - val_accuracy: 0.9047 - val_loss: 0.3018 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.9181 - loss: 0.2321 - val_accuracy: 0.9025 - val_loss: 0.3099 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.9217 - loss: 0.2241 - val_accuracy: 0.9033 - val_loss: 0.3083 - learning_rate: 3.1250e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 81ms/step - accuracy: 0.9219 - loss: 0.2196 - val_accuracy: 0.9049 - val_loss: 0.3002 - learning_rate: 3.1250e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 80ms/step - accuracy: 0.9206 - loss: 0.2275 - val_accuracy: 0.9062 - val_loss: 0.3011 - learning_rate: 3.1250e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.9218 - loss: 0.2220 - val_accuracy: 0.9061 - val_loss: 0.2999 - learning_rate: 1.5625e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9642\n",
            "Testing Accuracy: 0.9048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epochs = list(range(1, 51))\n",
        "train_accuracy = [\n",
        "    0.3347, 0.5418, 0.6407, 0.6931, 0.7246, 0.7438, 0.7637, 0.7790, 0.7935, 0.7995,\n",
        "    0.8089, 0.8325, 0.8418, 0.8488, 0.8533, 0.8559, 0.8591, 0.8625, 0.8663, 0.8659,\n",
        "    0.8694, 0.8752, 0.8751, 0.8794, 0.8814, 0.8869, 0.8936, 0.8933, 0.8998, 0.8991,\n",
        "    0.9012, 0.9016, 0.9017, 0.9073, 0.9114, 0.9117, 0.9089, 0.9118, 0.9144, 0.9164,\n",
        "    0.9171, 0.9168, 0.9184, 0.9159, 0.9202, 0.9181, 0.9217, 0.9219, 0.9206, 0.9218\n",
        "]\n",
        "val_accuracy = [\n",
        "    0.2507, 0.5851, 0.6834, 0.7126, 0.7255, 0.7365, 0.7691, 0.8088, 0.8087, 0.7326,\n",
        "    0.7659, 0.8196, 0.8513, 0.8598, 0.8307, 0.8619, 0.8583, 0.8656, 0.8723, 0.8679,\n",
        "    0.8249, 0.8778, 0.8784, 0.8733, 0.8708, 0.8845, 0.8867, 0.8804, 0.8915, 0.8934,\n",
        "    0.8899, 0.8891, 0.8919, 0.8937, 0.8931, 0.8983, 0.8987, 0.8998, 0.8996, 0.8985,\n",
        "    0.9026, 0.9060, 0.9048, 0.9055, 0.9047, 0.9025, 0.9033, 0.9049, 0.9062, 0.9061\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy', color='blue', marker='o', markersize=4)\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy', color='orange', marker='s', markersize=4)\n",
        "\n",
        "plt.title('CNN Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "plt.ylim(0.2, 1.0)\n",
        "\n",
        "plt.savefig('cnn_accuracy_plot.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "3NcgexKTh06m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DNN\n",
        "\n"
      ],
      "metadata": {
        "id": "t_FfrdF5iOQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"Load and preprocess CIFAR-10 dataset\"\"\"\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "def create_data_augmentation():\n",
        "    \"\"\"Create data augmentation pipeline\"\"\"\n",
        "    return ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "def build_dnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    \"\"\"Build and return the DNN model\"\"\"\n",
        "    model = models.Sequential([\n",
        "        # Input layer\n",
        "        layers.Input(shape=input_shape),\n",
        "\n",
        "        # First Convolutional Block\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        layers.Conv2D(256, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(256, (3, 3), padding='same', activation='relu',\n",
        "                     kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Dense Layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu', kernel_initializer='he_normal'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_callbacks():\n",
        "    \"\"\"Create training callbacks\"\"\"\n",
        "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    return [lr_scheduler, early_stopping]\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_and_preprocess_data()\n",
        "\n",
        "datagen = create_data_augmentation()\n",
        "\n",
        "model = build_dnn_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = create_callbacks()\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "plot_training_history(history)\n",
        "\n",
        "model.save('cifar10_dnn_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-t3se4QeXCQ",
        "outputId": "6fe90df2-7767-4500-b9ea-66bf2c0cc5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 112ms/step - accuracy: 0.3346 - loss: 2.1667 - val_accuracy: 0.4815 - val_loss: 1.4690 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.5406 - loss: 1.3225 - val_accuracy: 0.6380 - val_loss: 1.0597 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.6260 - loss: 1.0701 - val_accuracy: 0.6768 - val_loss: 0.9506 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.6796 - loss: 0.9074 - val_accuracy: 0.7091 - val_loss: 0.8746 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7155 - loss: 0.8163 - val_accuracy: 0.7666 - val_loss: 0.6935 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.7345 - loss: 0.7569 - val_accuracy: 0.7691 - val_loss: 0.6797 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.7512 - loss: 0.7093 - val_accuracy: 0.7641 - val_loss: 0.6868 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.7685 - loss: 0.6599 - val_accuracy: 0.7541 - val_loss: 0.7708 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.7839 - loss: 0.6215 - val_accuracy: 0.7857 - val_loss: 0.6627 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.8013 - loss: 0.5843 - val_accuracy: 0.8270 - val_loss: 0.5149 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.8037 - loss: 0.5700 - val_accuracy: 0.8141 - val_loss: 0.5579 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8130 - loss: 0.5396 - val_accuracy: 0.8302 - val_loss: 0.5100 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 80ms/step - accuracy: 0.8136 - loss: 0.5336 - val_accuracy: 0.8334 - val_loss: 0.4941 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.8278 - loss: 0.4983 - val_accuracy: 0.8495 - val_loss: 0.4423 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.8293 - loss: 0.4918 - val_accuracy: 0.8413 - val_loss: 0.4912 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8337 - loss: 0.4783 - val_accuracy: 0.8302 - val_loss: 0.5267 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.8453 - loss: 0.4585 - val_accuracy: 0.8305 - val_loss: 0.5141 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8581 - loss: 0.4135 - val_accuracy: 0.8703 - val_loss: 0.4002 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.8646 - loss: 0.3907 - val_accuracy: 0.8749 - val_loss: 0.3854 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.8676 - loss: 0.3812 - val_accuracy: 0.8708 - val_loss: 0.4008 - learning_rate: 5.0000e-04\n",
            "Training Accuracy: 0.9120\n",
            "Testing Accuracy: 0.8749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxfZVNhsiGvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet-18\n"
      ],
      "metadata": {
        "id": "fl7mRZqliHUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "model = ResNet18().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    print(f'Epoch {epoch}, Train Loss: {running_loss/len(trainloader):.4f}, Train Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    print(f'Validation Loss: {val_loss/len(testloader):.4f}, Validation Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "for epoch in range(100):\n",
        "    train(epoch)\n",
        "    validate()\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), 'resnet18_cifar10.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X-HB-hbB_oO",
        "outputId": "798fe531-e40f-4e02-b154-0ae1b4183bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 1.9631, Train Acc: 29.78%\n",
            "Validation Loss: 1.7023, Validation Acc: 36.17%\n",
            "Epoch 1, Train Loss: 1.4933, Train Acc: 44.87%\n",
            "Validation Loss: 1.4510, Validation Acc: 48.43%\n",
            "Epoch 2, Train Loss: 1.2172, Train Acc: 55.98%\n",
            "Validation Loss: 1.1823, Validation Acc: 58.97%\n",
            "Epoch 3, Train Loss: 1.0065, Train Acc: 64.04%\n",
            "Validation Loss: 0.9470, Validation Acc: 66.94%\n",
            "Epoch 4, Train Loss: 0.8423, Train Acc: 70.33%\n",
            "Validation Loss: 0.9092, Validation Acc: 68.18%\n",
            "Epoch 5, Train Loss: 0.7162, Train Acc: 75.04%\n",
            "Validation Loss: 0.7573, Validation Acc: 74.27%\n",
            "Epoch 6, Train Loss: 0.6260, Train Acc: 78.24%\n",
            "Validation Loss: 0.6320, Validation Acc: 78.08%\n",
            "Epoch 7, Train Loss: 0.5756, Train Acc: 80.31%\n",
            "Validation Loss: 0.6300, Validation Acc: 78.36%\n",
            "Epoch 8, Train Loss: 0.5445, Train Acc: 81.39%\n",
            "Validation Loss: 0.7071, Validation Acc: 75.88%\n",
            "Epoch 9, Train Loss: 0.5186, Train Acc: 82.21%\n",
            "Validation Loss: 0.6731, Validation Acc: 77.87%\n",
            "Epoch 10, Train Loss: 0.4995, Train Acc: 82.93%\n",
            "Validation Loss: 0.7246, Validation Acc: 76.39%\n",
            "Epoch 11, Train Loss: 0.4820, Train Acc: 83.42%\n",
            "Validation Loss: 0.6466, Validation Acc: 77.85%\n",
            "Epoch 12, Train Loss: 0.4647, Train Acc: 84.05%\n",
            "Validation Loss: 0.5536, Validation Acc: 81.28%\n",
            "Epoch 13, Train Loss: 0.4559, Train Acc: 84.32%\n",
            "Validation Loss: 0.6864, Validation Acc: 78.37%\n",
            "Epoch 14, Train Loss: 0.4418, Train Acc: 84.95%\n",
            "Validation Loss: 0.5420, Validation Acc: 81.21%\n",
            "Epoch 15, Train Loss: 0.4320, Train Acc: 85.17%\n",
            "Validation Loss: 0.5371, Validation Acc: 82.03%\n",
            "Epoch 16, Train Loss: 0.4205, Train Acc: 85.61%\n",
            "Validation Loss: 0.6073, Validation Acc: 79.25%\n",
            "Epoch 17, Train Loss: 0.4162, Train Acc: 85.84%\n",
            "Validation Loss: 0.6004, Validation Acc: 80.23%\n",
            "Epoch 18, Train Loss: 0.4027, Train Acc: 86.30%\n",
            "Validation Loss: 0.7931, Validation Acc: 75.81%\n",
            "Epoch 19, Train Loss: 0.3967, Train Acc: 86.39%\n",
            "Validation Loss: 0.6199, Validation Acc: 79.98%\n",
            "Epoch 20, Train Loss: 0.3914, Train Acc: 86.59%\n",
            "Validation Loss: 0.6780, Validation Acc: 78.71%\n",
            "Epoch 21, Train Loss: 0.3881, Train Acc: 86.71%\n",
            "Validation Loss: 0.5902, Validation Acc: 80.40%\n",
            "Epoch 22, Train Loss: 0.3804, Train Acc: 87.06%\n",
            "Validation Loss: 0.5040, Validation Acc: 82.91%\n",
            "Epoch 23, Train Loss: 0.3738, Train Acc: 87.29%\n",
            "Validation Loss: 0.5169, Validation Acc: 82.53%\n",
            "Epoch 24, Train Loss: 0.3744, Train Acc: 87.21%\n",
            "Validation Loss: 0.4710, Validation Acc: 84.06%\n",
            "Epoch 25, Train Loss: 0.3654, Train Acc: 87.50%\n",
            "Validation Loss: 0.7307, Validation Acc: 77.75%\n",
            "Epoch 26, Train Loss: 0.3643, Train Acc: 87.62%\n",
            "Validation Loss: 0.5122, Validation Acc: 83.27%\n",
            "Epoch 27, Train Loss: 0.3591, Train Acc: 87.77%\n",
            "Validation Loss: 0.4790, Validation Acc: 83.72%\n",
            "Epoch 28, Train Loss: 0.3525, Train Acc: 87.84%\n",
            "Validation Loss: 0.5057, Validation Acc: 83.46%\n",
            "Epoch 29, Train Loss: 0.3581, Train Acc: 87.79%\n",
            "Validation Loss: 0.6213, Validation Acc: 80.02%\n",
            "Epoch 30, Train Loss: 0.3476, Train Acc: 88.15%\n",
            "Validation Loss: 0.4188, Validation Acc: 86.08%\n",
            "Epoch 31, Train Loss: 0.3382, Train Acc: 88.37%\n",
            "Validation Loss: 0.4461, Validation Acc: 85.24%\n",
            "Epoch 32, Train Loss: 0.3392, Train Acc: 88.47%\n",
            "Validation Loss: 0.5012, Validation Acc: 83.67%\n",
            "Epoch 33, Train Loss: 0.3449, Train Acc: 88.27%\n",
            "Validation Loss: 0.4257, Validation Acc: 86.29%\n",
            "Epoch 34, Train Loss: 0.3401, Train Acc: 88.32%\n",
            "Validation Loss: 0.4525, Validation Acc: 85.15%\n",
            "Epoch 35, Train Loss: 0.3338, Train Acc: 88.52%\n",
            "Validation Loss: 0.4852, Validation Acc: 84.48%\n",
            "Epoch 36, Train Loss: 0.3354, Train Acc: 88.55%\n",
            "Validation Loss: 0.4751, Validation Acc: 84.44%\n",
            "Epoch 37, Train Loss: 0.3277, Train Acc: 88.78%\n",
            "Validation Loss: 0.4631, Validation Acc: 84.68%\n",
            "Epoch 38, Train Loss: 0.3323, Train Acc: 88.57%\n",
            "Validation Loss: 0.5356, Validation Acc: 82.91%\n",
            "Epoch 39, Train Loss: 0.3263, Train Acc: 88.83%\n",
            "Validation Loss: 0.4544, Validation Acc: 84.95%\n",
            "Epoch 40, Train Loss: 0.3238, Train Acc: 89.06%\n",
            "Validation Loss: 0.4302, Validation Acc: 85.47%\n",
            "Epoch 41, Train Loss: 0.3175, Train Acc: 89.10%\n",
            "Validation Loss: 0.5211, Validation Acc: 83.18%\n",
            "Epoch 42, Train Loss: 0.3223, Train Acc: 88.93%\n",
            "Validation Loss: 0.5336, Validation Acc: 82.74%\n",
            "Epoch 43, Train Loss: 0.3140, Train Acc: 89.42%\n",
            "Validation Loss: 0.4728, Validation Acc: 84.16%\n",
            "Epoch 44, Train Loss: 0.3106, Train Acc: 89.43%\n",
            "Validation Loss: 0.4589, Validation Acc: 84.91%\n",
            "Epoch 45, Train Loss: 0.3138, Train Acc: 89.30%\n",
            "Validation Loss: 0.3754, Validation Acc: 87.44%\n",
            "Epoch 46, Train Loss: 0.3142, Train Acc: 89.22%\n",
            "Validation Loss: 0.4504, Validation Acc: 85.25%\n",
            "Epoch 47, Train Loss: 0.3141, Train Acc: 89.39%\n",
            "Validation Loss: 0.4108, Validation Acc: 86.78%\n",
            "Epoch 48, Train Loss: 0.3035, Train Acc: 89.69%\n",
            "Validation Loss: 0.4308, Validation Acc: 85.48%\n",
            "Epoch 49, Train Loss: 0.3058, Train Acc: 89.54%\n",
            "Validation Loss: 0.4026, Validation Acc: 86.45%\n",
            "Epoch 50, Train Loss: 0.2999, Train Acc: 89.79%\n",
            "Validation Loss: 0.5369, Validation Acc: 83.31%\n",
            "Epoch 51, Train Loss: 0.2994, Train Acc: 89.80%\n",
            "Validation Loss: 0.5584, Validation Acc: 82.02%\n",
            "Epoch 52, Train Loss: 0.3013, Train Acc: 89.67%\n",
            "Validation Loss: 0.4313, Validation Acc: 85.58%\n",
            "Epoch 53, Train Loss: 0.3055, Train Acc: 89.48%\n",
            "Validation Loss: 0.4339, Validation Acc: 85.97%\n",
            "Epoch 54, Train Loss: 0.2992, Train Acc: 89.95%\n",
            "Validation Loss: 0.4457, Validation Acc: 85.40%\n",
            "Epoch 55, Train Loss: 0.2912, Train Acc: 90.01%\n",
            "Validation Loss: 0.4014, Validation Acc: 86.96%\n",
            "Epoch 56, Train Loss: 0.2949, Train Acc: 89.87%\n",
            "Validation Loss: 0.5721, Validation Acc: 81.29%\n",
            "Epoch 57, Train Loss: 0.2878, Train Acc: 90.12%\n",
            "Validation Loss: 0.5480, Validation Acc: 82.40%\n",
            "Epoch 58, Train Loss: 0.2896, Train Acc: 90.05%\n",
            "Validation Loss: 0.5947, Validation Acc: 81.24%\n",
            "Epoch 59, Train Loss: 0.2810, Train Acc: 90.38%\n",
            "Validation Loss: 0.3932, Validation Acc: 87.22%\n",
            "Epoch 60, Train Loss: 0.2854, Train Acc: 90.18%\n",
            "Validation Loss: 0.3784, Validation Acc: 86.94%\n",
            "Epoch 61, Train Loss: 0.2840, Train Acc: 90.31%\n",
            "Validation Loss: 0.4402, Validation Acc: 85.78%\n",
            "Epoch 62, Train Loss: 0.2776, Train Acc: 90.64%\n",
            "Validation Loss: 0.5387, Validation Acc: 83.66%\n",
            "Epoch 63, Train Loss: 0.2751, Train Acc: 90.63%\n",
            "Validation Loss: 0.4312, Validation Acc: 86.00%\n",
            "Epoch 64, Train Loss: 0.2677, Train Acc: 90.84%\n",
            "Validation Loss: 0.3523, Validation Acc: 88.47%\n",
            "Epoch 65, Train Loss: 0.2765, Train Acc: 90.43%\n",
            "Validation Loss: 0.4010, Validation Acc: 86.64%\n",
            "Epoch 66, Train Loss: 0.2640, Train Acc: 91.04%\n",
            "Validation Loss: 0.4476, Validation Acc: 85.29%\n",
            "Epoch 67, Train Loss: 0.2664, Train Acc: 90.85%\n",
            "Validation Loss: 0.4934, Validation Acc: 84.53%\n",
            "Epoch 68, Train Loss: 0.2706, Train Acc: 90.77%\n",
            "Validation Loss: 0.4285, Validation Acc: 86.44%\n",
            "Epoch 69, Train Loss: 0.2622, Train Acc: 91.07%\n",
            "Validation Loss: 0.4474, Validation Acc: 85.89%\n",
            "Epoch 70, Train Loss: 0.2660, Train Acc: 90.83%\n",
            "Validation Loss: 0.3766, Validation Acc: 88.09%\n",
            "Epoch 71, Train Loss: 0.2564, Train Acc: 91.19%\n",
            "Validation Loss: 0.4235, Validation Acc: 86.19%\n",
            "Epoch 72, Train Loss: 0.2579, Train Acc: 91.08%\n",
            "Validation Loss: 0.4103, Validation Acc: 86.41%\n",
            "Epoch 73, Train Loss: 0.2489, Train Acc: 91.44%\n",
            "Validation Loss: 0.4639, Validation Acc: 85.40%\n",
            "Epoch 74, Train Loss: 0.2525, Train Acc: 91.41%\n",
            "Validation Loss: 0.3803, Validation Acc: 87.28%\n",
            "Epoch 75, Train Loss: 0.2549, Train Acc: 91.32%\n",
            "Validation Loss: 0.4112, Validation Acc: 86.53%\n",
            "Epoch 76, Train Loss: 0.2485, Train Acc: 91.48%\n",
            "Validation Loss: 0.4416, Validation Acc: 85.31%\n",
            "Epoch 77, Train Loss: 0.2368, Train Acc: 91.84%\n",
            "Validation Loss: 0.4399, Validation Acc: 86.26%\n",
            "Epoch 78, Train Loss: 0.2415, Train Acc: 91.82%\n",
            "Validation Loss: 0.4028, Validation Acc: 87.30%\n",
            "Epoch 79, Train Loss: 0.2383, Train Acc: 91.89%\n",
            "Validation Loss: 0.8218, Validation Acc: 75.94%\n",
            "Epoch 80, Train Loss: 0.2410, Train Acc: 91.61%\n",
            "Validation Loss: 0.4711, Validation Acc: 85.64%\n",
            "Epoch 81, Train Loss: 0.2363, Train Acc: 91.88%\n",
            "Validation Loss: 0.5635, Validation Acc: 82.42%\n",
            "Epoch 82, Train Loss: 0.2320, Train Acc: 92.08%\n",
            "Validation Loss: 0.3081, Validation Acc: 89.84%\n",
            "Epoch 83, Train Loss: 0.2305, Train Acc: 92.02%\n",
            "Validation Loss: 0.4815, Validation Acc: 85.06%\n",
            "Epoch 84, Train Loss: 0.2268, Train Acc: 92.28%\n",
            "Validation Loss: 0.7375, Validation Acc: 77.84%\n",
            "Epoch 85, Train Loss: 0.2263, Train Acc: 92.23%\n",
            "Validation Loss: 0.4355, Validation Acc: 86.11%\n",
            "Epoch 86, Train Loss: 0.2256, Train Acc: 92.26%\n",
            "Validation Loss: 0.4138, Validation Acc: 86.98%\n",
            "Epoch 87, Train Loss: 0.2229, Train Acc: 92.44%\n",
            "Validation Loss: 0.3719, Validation Acc: 87.87%\n",
            "Epoch 88, Train Loss: 0.2214, Train Acc: 92.49%\n",
            "Validation Loss: 0.3848, Validation Acc: 87.52%\n",
            "Epoch 89, Train Loss: 0.2176, Train Acc: 92.66%\n",
            "Validation Loss: 0.3627, Validation Acc: 88.18%\n",
            "Epoch 90, Train Loss: 0.2093, Train Acc: 92.76%\n",
            "Validation Loss: 0.3427, Validation Acc: 88.72%\n",
            "Epoch 91, Train Loss: 0.2125, Train Acc: 92.76%\n",
            "Validation Loss: 0.3677, Validation Acc: 88.34%\n",
            "Epoch 92, Train Loss: 0.2120, Train Acc: 92.71%\n",
            "Validation Loss: 0.3155, Validation Acc: 89.92%\n",
            "Epoch 93, Train Loss: 0.2051, Train Acc: 92.93%\n",
            "Validation Loss: 0.3512, Validation Acc: 88.55%\n",
            "Epoch 94, Train Loss: 0.2058, Train Acc: 92.87%\n",
            "Validation Loss: 0.3825, Validation Acc: 87.58%\n",
            "Epoch 95, Train Loss: 0.2044, Train Acc: 93.12%\n",
            "Validation Loss: 0.3798, Validation Acc: 87.70%\n",
            "Epoch 96, Train Loss: 0.2013, Train Acc: 93.04%\n",
            "Validation Loss: 0.3599, Validation Acc: 88.58%\n",
            "Epoch 97, Train Loss: 0.2016, Train Acc: 93.19%\n",
            "Validation Loss: 0.3635, Validation Acc: 88.25%\n",
            "Epoch 98, Train Loss: 0.1921, Train Acc: 93.49%\n",
            "Validation Loss: 0.3576, Validation Acc: 88.26%\n",
            "Epoch 99, Train Loss: 0.1944, Train Acc: 93.41%\n",
            "Validation Loss: 0.3780, Validation Acc: 87.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epochs = list(range(100))\n",
        "train_accuracy = [\n",
        "    29.78, 44.87, 55.98, 64.04, 70.33, 75.04, 78.24, 80.31, 81.39, 82.21,\n",
        "    82.93, 83.42, 84.05, 84.32, 84.95, 85.17, 85.61, 85.84, 86.30, 86.39,\n",
        "    86.59, 86.71, 87.06, 87.29, 87.21, 87.50, 87.62, 87.77, 87.84, 87.79,\n",
        "    88.15, 88.37, 88.47, 88.27, 88.32, 88.52, 88.55, 88.78, 88.57, 88.83,\n",
        "    89.06, 89.10, 88.93, 89.42, 89.43, 89.30, 89.22, 89.39, 89.69, 89.54,\n",
        "    89.79, 89.80, 89.67, 89.48, 89.95, 90.01, 89.87, 90.12, 90.05, 90.38,\n",
        "    90.18, 90.31, 90.64, 90.63, 90.84, 90.43, 91.04, 90.85, 90.77, 91.07,\n",
        "    90.83, 91.19, 91.08, 91.44, 91.41, 91.32, 91.48, 91.84, 91.82, 91.89,\n",
        "    91.61, 91.88, 92.08, 92.02, 92.28, 92.23, 92.26, 92.44, 92.49, 92.66,\n",
        "    92.76, 92.76, 92.71, 92.93, 92.87, 93.12, 93.04, 93.19, 93.49, 93.41\n",
        "]\n",
        "val_accuracy = [\n",
        "    36.17, 48.43, 58.97, 66.94, 68.18, 74.27, 78.08, 78.36, 75.88, 77.87,\n",
        "    76.39, 77.85, 81.28, 78.37, 81.21, 82.03, 79.25, 80.23, 75.81, 79.98,\n",
        "    78.71, 80.40, 82.91, 82.53, 84.06, 77.75, 83.27, 83.72, 83.46, 80.02,\n",
        "    86.08, 85.24, 83.67, 86.29, 85.15, 84.48, 84.44, 84.68, 82.91, 84.95,\n",
        "    85.47, 83.18, 82.74, 84.16, 84.91, 87.44, 85.25, 86.78, 85.48, 86.45,\n",
        "    83.31, 82.02, 85.58, 85.97, 85.40, 86.96, 81.29, 82.40, 81.24, 87.22,\n",
        "    86.94, 85.78, 83.66, 86.00, 88.47, 86.64, 85.29, 84.53, 86.44, 85.89,\n",
        "    88.09, 86.19, 86.41, 85.40, 87.28, 86.53, 85.31, 86.26, 75.94, 85.64,\n",
        "    82.42, 89.84, 85.06, 77.84, 86.11, 86.98, 87.87, 87.52, 88.18, 88.72,\n",
        "    88.34, 89.92, 88.55, 87.58, 87.70, 88.58, 88.25, 88.26, 87.48,89.25\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy', color='blue', marker='o', markersize=4)\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy', color='orange', marker='s', markersize=4)\n",
        "\n",
        "plt.title('ResNet-18 Training and Validation Accuracy:')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "plt.ylim(20, 100)\n",
        "\n",
        "plt.savefig('resnet18_accuracy_plot.png')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "yFRYPJT8HXXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AS I presented my ppt in final class, I said for future work we can use swin transformer to obtain better and efficient accuracy.\n",
        "\n",
        "so following the the code and results for the cifar-10 dataset with swin transformer."
      ],
      "metadata": {
        "id": "j6L80FR07jPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-2\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                        std=[0.2023, 0.1994, 0.2010]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                        std=[0.2023, 0.1994, 0.2010]),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained Swin Transformer model\n",
        "model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=10)\n",
        "model = model.to(device)\n",
        "\n",
        "# optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                epoch_train_accuracy = 100 * correct / total\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], '\n",
        "                      f'Loss: {running_loss/100:.4f}, Training Accuracy: {epoch_train_accuracy:.2f}%')\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "\n",
        "        epoch_train_accuracy = evaluate_model(train_loader)\n",
        "        train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "        test_accuracy = evaluate_model(test_loader)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {epoch_train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "def evaluate_model(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    model.train()\n",
        "    return accuracy\n",
        "\n",
        "print(\"Starting training...\")\n",
        "train_model()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Testing Accuracy', marker='o')\n",
        "plt.title('Training vs Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig('train_test_accuracy.png')\n",
        "\n",
        "final_accuracy = evaluate_model(test_loader)\n",
        "print(f'Final Test Accuracy: {final_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7934f5ad3fa42a6a3e0e9d01dcf74e5",
            "bff47057fdc648b5bd11bf3fa300e8bc",
            "6c3b0d2a632d4c27946987f4d27ef5f5",
            "2ced38269ca84e50be868d892682f355",
            "f8b913cfa2cf45df8bca5c2e97a8f2b8",
            "476d9f2df23d4d7b9dfc780476afb565",
            "fe8f8ef5208a415cbe0b9be17544d1f1",
            "d7d005469841479a9ee7d2875f9974bc",
            "f111fb7114cb4c0f901a6172a1b4f84c",
            "6bbae917dda34b0d8a19e8ec5fa39420",
            "f4e5e6d3520e4968bca1db2b1b4f00d5"
          ]
        },
        "id": "55bn5rzr8vJE",
        "outputId": "cd2f848f-199e-49d2-ec5a-794d986457ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 40.9MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7934f5ad3fa42a6a3e0e9d01dcf74e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1/10], Step [100], Loss: 0.5433, Training Accuracy: 82.62%\n",
            "Epoch [1/10], Step [200], Loss: 0.2385, Training Accuracy: 92.28%\n",
            "Epoch [1/10], Step [300], Loss: 0.2038, Training Accuracy: 93.47%\n",
            "Epoch [1/10], Step [400], Loss: 0.2087, Training Accuracy: 93.38%\n",
            "Epoch [1/10], Step [500], Loss: 0.1686, Training Accuracy: 94.55%\n",
            "Epoch [1/10], Step [600], Loss: 0.1684, Training Accuracy: 94.33%\n",
            "Epoch [1/10], Step [700], Loss: 0.1604, Training Accuracy: 94.83%\n",
            "Epoch [1/10], Train Accuracy: 97.47%, Test Accuracy: 96.10%\n",
            "Epoch [2/10], Step [100], Loss: 0.0949, Training Accuracy: 96.94%\n",
            "Epoch [2/10], Step [200], Loss: 0.1181, Training Accuracy: 96.23%\n",
            "Epoch [2/10], Step [300], Loss: 0.1066, Training Accuracy: 96.42%\n",
            "Epoch [2/10], Step [400], Loss: 0.1009, Training Accuracy: 96.61%\n",
            "Epoch [2/10], Step [500], Loss: 0.1028, Training Accuracy: 96.53%\n",
            "Epoch [2/10], Step [600], Loss: 0.0999, Training Accuracy: 96.67%\n",
            "Epoch [2/10], Step [700], Loss: 0.1149, Training Accuracy: 96.12%\n",
            "Epoch [2/10], Train Accuracy: 98.05%, Test Accuracy: 96.08%\n",
            "Epoch [3/10], Step [100], Loss: 0.0761, Training Accuracy: 97.52%\n",
            "Epoch [3/10], Step [200], Loss: 0.0595, Training Accuracy: 97.89%\n",
            "Epoch [3/10], Step [300], Loss: 0.0797, Training Accuracy: 97.16%\n",
            "Epoch [3/10], Step [400], Loss: 0.0750, Training Accuracy: 97.42%\n",
            "Epoch [3/10], Step [500], Loss: 0.0675, Training Accuracy: 97.73%\n",
            "Epoch [3/10], Step [600], Loss: 0.0646, Training Accuracy: 98.05%\n",
            "Epoch [3/10], Step [700], Loss: 0.0771, Training Accuracy: 97.33%\n",
            "Epoch [3/10], Train Accuracy: 98.81%, Test Accuracy: 96.33%\n",
            "Epoch [4/10], Step [100], Loss: 0.0421, Training Accuracy: 98.66%\n",
            "Epoch [4/10], Step [200], Loss: 0.0367, Training Accuracy: 98.81%\n",
            "Epoch [4/10], Step [300], Loss: 0.0375, Training Accuracy: 98.78%\n",
            "Epoch [4/10], Step [400], Loss: 0.0497, Training Accuracy: 98.22%\n",
            "Epoch [4/10], Step [500], Loss: 0.0439, Training Accuracy: 98.44%\n",
            "Epoch [4/10], Step [600], Loss: 0.0527, Training Accuracy: 98.14%\n",
            "Epoch [4/10], Step [700], Loss: 0.0543, Training Accuracy: 98.27%\n",
            "Epoch [4/10], Train Accuracy: 99.49%, Test Accuracy: 97.03%\n",
            "Epoch [5/10], Step [100], Loss: 0.0291, Training Accuracy: 99.14%\n",
            "Epoch [5/10], Step [200], Loss: 0.0272, Training Accuracy: 99.23%\n",
            "Epoch [5/10], Step [300], Loss: 0.0367, Training Accuracy: 98.77%\n",
            "Epoch [5/10], Step [400], Loss: 0.0312, Training Accuracy: 98.89%\n",
            "Epoch [5/10], Step [500], Loss: 0.0431, Training Accuracy: 98.50%\n",
            "Epoch [5/10], Step [600], Loss: 0.0350, Training Accuracy: 98.84%\n",
            "Epoch [5/10], Step [700], Loss: 0.0338, Training Accuracy: 98.89%\n",
            "Epoch [5/10], Train Accuracy: 99.52%, Test Accuracy: 96.78%\n",
            "Epoch [6/10], Step [100], Loss: 0.0174, Training Accuracy: 99.41%\n",
            "Epoch [6/10], Step [200], Loss: 0.0162, Training Accuracy: 99.38%\n",
            "Epoch [6/10], Step [300], Loss: 0.0158, Training Accuracy: 99.50%\n",
            "Epoch [6/10], Step [400], Loss: 0.0119, Training Accuracy: 99.62%\n",
            "Epoch [6/10], Step [500], Loss: 0.0220, Training Accuracy: 99.23%\n",
            "Epoch [6/10], Step [600], Loss: 0.0179, Training Accuracy: 99.47%\n",
            "Epoch [6/10], Step [700], Loss: 0.0252, Training Accuracy: 99.06%\n",
            "Epoch [6/10], Train Accuracy: 99.68%, Test Accuracy: 96.95%\n",
            "Epoch [7/10], Step [100], Loss: 0.0138, Training Accuracy: 99.59%\n",
            "Epoch [7/10], Step [200], Loss: 0.0124, Training Accuracy: 99.61%\n",
            "Epoch [7/10], Step [300], Loss: 0.0107, Training Accuracy: 99.64%\n",
            "Epoch [7/10], Step [400], Loss: 0.0150, Training Accuracy: 99.52%\n",
            "Epoch [7/10], Step [500], Loss: 0.0105, Training Accuracy: 99.62%\n",
            "Epoch [7/10], Step [600], Loss: 0.0094, Training Accuracy: 99.70%\n",
            "Epoch [7/10], Step [700], Loss: 0.0110, Training Accuracy: 99.75%\n",
            "Epoch [7/10], Train Accuracy: 99.83%, Test Accuracy: 97.40%\n",
            "Epoch [8/10], Step [100], Loss: 0.0092, Training Accuracy: 99.73%\n",
            "Epoch [8/10], Step [200], Loss: 0.0057, Training Accuracy: 99.89%\n",
            "Epoch [8/10], Step [300], Loss: 0.0079, Training Accuracy: 99.77%\n",
            "Epoch [8/10], Step [400], Loss: 0.0066, Training Accuracy: 99.80%\n",
            "Epoch [8/10], Step [500], Loss: 0.0049, Training Accuracy: 99.88%\n",
            "Epoch [8/10], Step [600], Loss: 0.0073, Training Accuracy: 99.78%\n",
            "Epoch [8/10], Step [700], Loss: 0.0068, Training Accuracy: 99.69%\n",
            "Epoch [8/10], Train Accuracy: 99.96%, Test Accuracy: 97.76%\n",
            "Epoch [9/10], Step [100], Loss: 0.0080, Training Accuracy: 99.83%\n",
            "Epoch [9/10], Step [200], Loss: 0.0048, Training Accuracy: 99.86%\n",
            "Epoch [9/10], Step [300], Loss: 0.0042, Training Accuracy: 99.88%\n",
            "Epoch [9/10], Step [400], Loss: 0.0036, Training Accuracy: 99.92%\n",
            "Epoch [9/10], Step [500], Loss: 0.0031, Training Accuracy: 99.94%\n",
            "Epoch [9/10], Step [600], Loss: 0.0046, Training Accuracy: 99.84%\n",
            "Epoch [9/10], Step [700], Loss: 0.0031, Training Accuracy: 99.92%\n",
            "Epoch [9/10], Train Accuracy: 100.00%, Test Accuracy: 97.93%\n",
            "Epoch [10/10], Step [100], Loss: 0.0044, Training Accuracy: 99.88%\n",
            "Epoch [10/10], Step [200], Loss: 0.0034, Training Accuracy: 99.92%\n",
            "Epoch [10/10], Step [300], Loss: 0.0042, Training Accuracy: 99.88%\n",
            "Epoch [10/10], Step [400], Loss: 0.0025, Training Accuracy: 99.94%\n",
            "Epoch [10/10], Step [500], Loss: 0.0030, Training Accuracy: 99.94%\n",
            "Epoch [10/10], Step [600], Loss: 0.0040, Training Accuracy: 99.89%\n",
            "Epoch [10/10], Step [700], Loss: 0.0037, Training Accuracy: 99.91%\n",
            "Epoch [10/10], Train Accuracy: 99.99%, Test Accuracy: 97.98%\n",
            "Final Test Accuracy: 97.98%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}